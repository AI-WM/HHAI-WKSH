{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-Heuristic A.I. Workshop\n",
    "\n",
    "Note for Event 1 by [Contributors](#Contributors)\n",
    "\n",
    "## Contents\n",
    "\n",
    "- [Coefficient of Determination](#Coefficient-of-Determination)\n",
    "\n",
    "- [RMSLE](#RMSLE)\n",
    "\n",
    "- [Overfitting](#Overfitting)\n",
    "\n",
    "- [Hyperparameter](#Hyperparameter)\n",
    "\n",
    "- [Bootstrap Aggregating](#Bootstrap-Aggregating)\n",
    "\n",
    "- [Out-Of-Bag Error](#Out-Of-Bag-Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficient of Determination\n",
    "\n",
    "#### Definition\n",
    "\n",
    "- Denoted $R^2$\n",
    "\n",
    "\n",
    "- Used to explain how many percentage of the variance of the original data the model could cover\n",
    "\n",
    "#### Formula\n",
    "\n",
    "- $R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$\n",
    "\n",
    "\n",
    "- $SS_{tot} = \\sum_{i=1}^{n}(y_i-\\bar{y})^2$\n",
    "\n",
    "\n",
    "- $SS_{reg} = \\sum_{i=1}^{n}(p_i-\\bar{y})^2$\n",
    "\n",
    "\n",
    "- $SS_{res} = \\sum_{i=1}^{n}(y_i-p_i)^2$\n",
    "\n",
    "\n",
    "#### The range of $R^2$\n",
    "\n",
    "- $R^2 \\in (-\\infty, 1]$\n",
    "\n",
    "\n",
    "- If $SS_{res} > SS_{tot}$, then $R^2$ become negative\n",
    "\n",
    "\n",
    "- The $R^2 < 0$ means the model get a worse result than using the mean value\n",
    "\n",
    "    \n",
    "#### How to determine that higher $R^2$ is not overfitting?\n",
    "\n",
    "- Adjusted $R^2$\n",
    "\n",
    "- AIC\n",
    "\n",
    "- BIC\n",
    "\n",
    "#### How to use R² in business interpretation?\n",
    "\n",
    "- Determine the model is good or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSLE\n",
    "\n",
    "#### RMSE\n",
    "\n",
    "- RMSE $= \\sqrt{MSE}$\n",
    "\n",
    "\n",
    "- MSE $= \\frac{1}{n}\\sum_{t=1}^{n}(obs_t - pre_t)^2$\n",
    "\n",
    "\n",
    "#### How to compute RMSLE?\n",
    "\n",
    "- RMSLE is Root Mean Squared Logarithmic Error, which is RMSE with $\\log$\n",
    "\n",
    "\n",
    "- RMSLE $= \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n}{( \\log(p_i + 1) - \\log(a_i + 1) )^2} }$\n",
    "\n",
    "    - $n$ is the total number of observations in the data set\n",
    "    \n",
    "    - $p$ is prediction\n",
    "    \n",
    "    - $a$ is actual response\n",
    "\n",
    "#### Why use $\\log$?\n",
    "\n",
    "- It is the way to make predictions smaller and more comparable\n",
    "\n",
    "\n",
    "- To scale the predictions (outputs), making them less sensitive to the difference on small digits (e.g. the difference of digits in tens or in thousands when the outputs are showed in digits in millions)\n",
    "\n",
    "\n",
    "- To transfer the outputs and focus on the increasing ratio rather that increasing quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "- Low training error, but high testing error\n",
    "\n",
    "\n",
    "- Random Forest helps eliminate the problem of overfitting which exists in decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter\n",
    "\n",
    "- Is a parameter whose value is set before the learning process begins. By contrast, the values of other parameters are derived via training.\n",
    "\n",
    "\n",
    "- Cannot be learned directly from the data in the standard model training process and need to be predefined.\n",
    "\n",
    "\n",
    "- Can be decided by setting different values, training different models, and choosing the values that test better\n",
    "\n",
    "\n",
    "- Some examples of hyperparameter:\n",
    "\n",
    "\n",
    "    - k in k-nearest neighbors\n",
    "\n",
    "    - Number of clusters in a k-means clustering\n",
    "\n",
    "    - Number of leaves or depth of a decision tree\n",
    "    \n",
    "    - Number of hidden layers in a deep neural network\n",
    "\n",
    "    - Learning Rate (in many models)\n",
    "\n",
    "\n",
    "- We can tune hyperparameter again and again in the model to find the fittest ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Aggregating\n",
    "\n",
    "- Also called Bagging\n",
    "\n",
    "\n",
    "- Is a machine learning ensemble algorithm designed to improve the stability and accuracy of machine learning algorithms used in classification and regression.\n",
    "\n",
    "\n",
    "- Could also use to reduce variance and help to avoid overfitting\n",
    "\n",
    "\n",
    "- Help reduce the impact of outlier on the model if using bootstrapping and create many trees to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-Of-Bag Error\n",
    "\n",
    "- Also called OOB error\n",
    "\n",
    "\n",
    "- A method of measuring the prediction error of random forests, boosted decision trees, and other machine learning models utilizing bootstrap aggregating (bagging) to sub-sample data samples used for training\n",
    "\n",
    "\n",
    "- The mean prediction error on each training sample xᵢ, using only the trees that did not have xᵢ in their bootstrap sample\n",
    "\n",
    "\n",
    "- If we use OOB to evaluate the model, we don’t need to use cross validation.\n",
    "\n",
    "\n",
    "- In random forest model, OOB is usually lower than the $R^2$ of training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributors\n",
    "\n",
    "*The list is sorted by last name, first name, and nickname.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
